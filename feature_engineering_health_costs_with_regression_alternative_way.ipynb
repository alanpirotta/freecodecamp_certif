{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_engineering_health_costs_with_regression alternative way.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alanpirotta/freecodecamp_certif/blob/main/feature_engineering_health_costs_with_regression_alternative_way.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TX15KOkPBV"
      },
      "source": [
        "*Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI*\n",
        "\n",
        "---\n",
        "\n",
        "In this challenge, you will predict healthcare costs using a regression algorithm.\n",
        "\n",
        "You are given a dataset that contains information about different people including their healthcare costs. Use the data to predict healthcare costs based on new data.\n",
        "\n",
        "The first two cells of this notebook import libraries and the data.\n",
        "\n",
        "Make sure to convert categorical data to numbers. Use 80% of the data as the `train_dataset` and 20% of the data as the `test_dataset`.\n",
        "\n",
        "`pop` off the \"expenses\" column from these datasets to create new datasets called `train_labels` and `test_labels`. Use these labels when training your model.\n",
        "\n",
        "Create a model and train it with the `train_dataset`. Run the final cell in this notebook to check your model. The final cell will use the unseen `test_dataset` to check how well the model generalizes.\n",
        "\n",
        "To pass the challenge, `model.evaluate` must return a Mean Absolute Error of under 3500. This means it predicts health care costs correctly within $3500.\n",
        "\n",
        "The final cell will also predict expenses using the `test_dataset` and graph the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX2FI4gZtTt"
      },
      "source": [
        "# Import data\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change categorical data to numbers.\n",
        "Binary if possible"
      ],
      "metadata": {
        "id": "TCWlOSxxwBB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature = \"region\"\n",
        "# classes = dataset[feature].unique().tolist()\n",
        "# print(f\"Feature classes: {classes}\")\n",
        "\n",
        "# dataset[feature] = dataset[feature].map(classes.index)\n",
        "\n",
        "# More manual Alternative \n",
        "# dataset['region'] = dataset['region'].replace({'southeast': 0,\n",
        "#                                               'southwest': 1,\n",
        "#                                               'northwest': 2,\n",
        "#                                               'northeast': 3\n",
        "#                                             })\n",
        "# print(dataset['region'].value_counts())\n",
        "# dataset.tail()"
      ],
      "metadata": {
        "id": "4OjuJKiSwk_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset['smoker'] = np.where(dataset['smoker']=='yes',1,0)\n",
        "# print(dataset['smoker'].value_counts())\n",
        "# dataset.tail()"
      ],
      "metadata": {
        "id": "0brTGHEywPVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcopvQh3X-kX"
      },
      "source": [
        "# dataset['sex'] = np.where(dataset['sex']=='male',1,0)\n",
        "# print(dataset['sex'].value_counts())\n",
        "# dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split between train and test datasets"
      ],
      "metadata": {
        "id": "mHncxWp41Ysm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(dataset, test_size=0.2)\n",
        "print(f'train shape: {train_df.shape}')\n",
        "print(f'test shape: {test_df.shape}')\n",
        "train_df.tail()"
      ],
      "metadata": {
        "id": "wZ309r4gyu5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_df.pop('expenses')\n",
        "test_labels = test_df.pop('expenses')"
      ],
      "metadata": {
        "id": "SA_KNOl1jliF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature engineering"
      ],
      "metadata": {
        "id": "f0Y3zA-uVJXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####region OneHotEncoding"
      ],
      "metadata": {
        "id": "3_Aw_NdKOvYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer "
      ],
      "metadata": {
        "id": "y4-aWEqiN0Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder() \n",
        "encoder.fit(train_df[['region']])\n",
        "re = encoder.transform(train_df[['region']]).todense()\n",
        "type(re)"
      ],
      "metadata": {
        "id": "0d-SRCnDPP3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re_df = pd.DataFrame(re, columns=encoder.categories_, index=train_df[['region']].index)\n",
        "re_df"
      ],
      "metadata": {
        "id": "ofIO_hZnQ2GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last cells where to test OneHotEncoder, next cells i'll make the transform to all applicable features."
      ],
      "metadata": {
        "id": "2xmsi6XIwIAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encode = ColumnTransformer ([\n",
        "                                     (\n",
        "                                      'one_hot_encode',   #Transformation name\n",
        "                                      OneHotEncoder(sparse=False),   #transformer to use\n",
        "                                      ['region', 'sex', 'smoker']    #features to transform\n",
        "                                     )\n",
        "                  ])\n",
        "one_hot_encode.fit(train_df)"
      ],
      "metadata": {
        "id": "NPQVyoVgYmEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_sex_smoker = one_hot_encode.transform(train_df)\n",
        "region_sex_smoker_df = pd.DataFrame(region_sex_smoker, index=train_df.index)"
      ],
      "metadata": {
        "id": "AODyOr6oaUnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_sex_smoker_test = one_hot_encode.transform(test_df)\n",
        "region_sex_smoker_test_df = pd.DataFrame(region_sex_smoker_test, index=test_df.index)"
      ],
      "metadata": {
        "id": "eLZrU_DffE9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Scaling"
      ],
      "metadata": {
        "id": "4WzGaMXoVGsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler, MaxAbsScaler"
      ],
      "metadata": {
        "id": "ZHSOPfiNVRGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaler = MaxAbsScaler()\n",
        "# scaler.fit(train_df[['bmi']])\n",
        "# bmi_scaled = scaler.transform(train_df[['bmi']])"
      ],
      "metadata": {
        "id": "GSRFDnHWVmKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.DataFrame({'original': train_df['bmi'].values, 'scaled': bmi_scaled.squeeze()}).describe()"
      ],
      "metadata": {
        "id": "g_3XvskfWG5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled_bmi_df = pd.DataFrame(bmi_scaled, columns=['bmi_scaled'], index=train_df[['bmi']].index)"
      ],
      "metadata": {
        "id": "jMybiKG2Xqbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_encoding = ColumnTransformer([\n",
        "                            (\n",
        "                             'MinMaxScaler_encoding',\n",
        "                             MinMaxScaler(),\n",
        "                             ['age', 'bmi']\n",
        "                            )\n",
        "          ])\n",
        "scaler_encoding.fit(train_df)"
      ],
      "metadata": {
        "id": "Jyqsp08xbLOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_bmi = scaler_encoding.transform(train_df)\n",
        "age_bmi_df = pd.DataFrame(age_bmi, index=train_df.index)"
      ],
      "metadata": {
        "id": "XUO_pdKmcx4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_bmi_test = scaler_encoding.transform(test_df)\n",
        "age_bmi_test_df = pd.DataFrame(age_bmi_test, index=test_df.index)"
      ],
      "metadata": {
        "id": "jxowTMTEh0Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_scaler_encoding = ColumnTransformer([\n",
        "                            (\n",
        "                             'RobustScaler_encoding',\n",
        "                             RobustScaler(),\n",
        "                             ['children']\n",
        "                            )\n",
        "          ])\n",
        "r_scaler_encoding.fit(train_df)"
      ],
      "metadata": {
        "id": "W4lcMYOFhIDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "children = r_scaler_encoding.transform(train_df)\n",
        "children_df = pd.DataFrame(children, index=train_df.index)"
      ],
      "metadata": {
        "id": "LR5poPF4hVHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "children_test = r_scaler_encoding.transform(test_df)\n",
        "children_test_df = pd.DataFrame(children_test, index=test_df.index)"
      ],
      "metadata": {
        "id": "nnZv9TIjh8AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = pd.concat([region_sex_smoker_df, age_bmi_df,children_df], axis=1)\n",
        "train_dataset.shape"
      ],
      "metadata": {
        "id": "MXVhcumcdy6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = pd.concat([region_sex_smoker_test_df, age_bmi_test_df,children_test_df], axis=1)\n",
        "test_dataset.shape"
      ],
      "metadata": {
        "id": "oVte0wOkiGq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Quick Test with linear regression"
      ],
      "metadata": {
        "id": "_-0888qNjLru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "lr = LinearRegression()"
      ],
      "metadata": {
        "id": "m2MGYUD5jVdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(train_dataset, train_labels)\n",
        "train_prediction = lr.predict(train_dataset)\n",
        "train_mae = mean_absolute_error(train_prediction, train_labels)\n",
        "train_mae"
      ],
      "metadata": {
        "id": "SdFhXZ5VjXKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = lr.predict(test_dataset)\n",
        "test_mae = mean_absolute_error(test_pred, test_labels)\n",
        "test_mae"
      ],
      "metadata": {
        "id": "-FDjXXf5jdhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train score: {lr.score(train_dataset,train_labels)}')\n",
        "print(f'Test score: {lr.score(test_dataset,test_labels)}')"
      ],
      "metadata": {
        "id": "ouTUpflrjfDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model"
      ],
      "metadata": {
        "id": "P4df61LI1ZJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = layers.experimental.preprocessing.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_dataset))"
      ],
      "metadata": {
        "id": "vcQEj0Vo9ejI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(2, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error',\n",
        "    metrics=['mae', 'mse'])"
      ],
      "metadata": {
        "id": "0-FUOu1r5nLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset, train_labels, \n",
        "    epochs=100,\n",
        "    # suppress logging\n",
        "    # verbose=0,\n",
        "    # Calculate validation results on 20% of the training data\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "gjYe18IC1a0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lxpVPSWi5jJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "print('loss',loss,'mae',mae,'mse',mse)"
      ],
      "metadata": {
        "id": "C9ebGXYW5iV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Partial-Conclusion:\n",
        "With all the feature-engineering i did, the linear regression score stayed practically the same, but the MAE decreased 13% from the results with only labelEncoding."
      ],
      "metadata": {
        "id": "7LLHUBzZlUPR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: This model works great for lower expenses and passable for really high ones, but in the middle doesn't work. The original way i tried with randomForest achieved a better result. I think this model can be improved."
      ],
      "metadata": {
        "id": "hBkBHmy08R1q"
      }
    }
  ]
}